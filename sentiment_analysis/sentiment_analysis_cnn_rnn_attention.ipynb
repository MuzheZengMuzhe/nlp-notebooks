{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification and Data Sets\n",
    "\n",
    "\n",
    "Text classification is a common task in natural language processing, which transforms a sequence of text of indefinite length into a category of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Sentiment Classification Data\n",
    "\n",
    "We use Stanford's Large Movie Review Dataset as the data set for text sentiment classification[1]. This data set is divided into two data sets for training and testing purposes, each containing 25,000 movie reviews downloaded from IMDb. In each data set, the number of comments labeled as \"positive\" and \"negative\" is equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "23"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(size=49342, unk=\"<unk>\", reserved=\"['<pad>', '<bos>', '<eos>']\")\n"
     ]
    }
   ],
   "source": [
    "from utils import load_data_imdb\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_iter,test_iter, vocab = load_data_imdb(batch_size)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using a Bag of Context Free Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:36:50.290407Z",
     "start_time": "2019-04-18T18:36:49.391263Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import gluonnlp as nlp\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, rnn, utils as gutils\n",
    "import gluonnlp as nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## Average Embeddings of a Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:20.147984Z",
     "start_time": "2019-04-18T18:37:20.140947Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "46"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class ContinuousBagOfWords(nn.HybridBlock):\n",
    "    def __init__(self, vocab_size, embed_size, **kwargs):\n",
    "        super(ContinuousBagOfWords, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.encoder = nn.HybridLambda(lambda F, x: F.mean(x, axis=1))\n",
    "        self.decoder = nn.Dense(2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # The shape of inputs is (batch size, number of words).\n",
    "        embeddings = self.embedding(inputs)\n",
    "        encoding = self.encoder(embeddings)\n",
    "        outputs = self.decoder(encoding)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Create a the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:25.447434Z",
     "start_time": "2019-04-18T18:37:20.149858Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "embed_size, ctx = 100, [mx.gpu(0)]\n",
    "net = ContinuousBagOfWords(len(vocab), embed_size)\n",
    "net.hybridize()\n",
    "net.initialize(init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load Pre-trained Word Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:40.206184Z",
     "start_time": "2019-04-18T18:37:25.449068Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49342, 100)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embedding = nlp.embedding.create('glove', source='glove.6B.100d')\n",
    "idx_to_vec = glove_embedding[vocab.idx_to_token]\n",
    "idx_to_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Use these word vectors as feature vectors for each word in the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:40.210859Z",
     "start_time": "2019-04-18T18:37:40.207714Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "47"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "net.embedding.weight.set_data(idx_to_vec)\n",
    "net.embedding.collect_params().setattr('grad_req', 'null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train and Evaluate the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.801349Z",
     "start_time": "2019-04-18T18:37:40.212205Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "48"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.538, train acc 0.751, test acc 0.747\n",
      "32697.6 exampes/sec on [gpu(0)]\n"
     ]
    }
   ],
   "source": [
    "from utils import train\n",
    "\n",
    "lr, num_epochs = 0.01, 5\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr})\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "train(net, train_iter, test_iter, loss, trainer, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Define the prediction function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.806821Z",
     "start_time": "2019-04-18T18:41:09.802933Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "49"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict_sentiment(net, vocab, sentence):\n",
    "    sentence = nd.array(vocab[sentence.split()], ctx=ctx[0])\n",
    "    label = nd.argmax(net(sentence.reshape((1, -1))), axis=1)\n",
    "    return 'positive' if label.asscalar() == 1 else 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then, use the trained model to classify the sentiments of two simple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.814658Z",
     "start_time": "2019-04-18T18:41:09.808150Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "50"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.821180Z",
     "start_time": "2019-04-18T18:41:09.816015Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Convolutional Neural Networks (textCNN)\n",
    "\n",
    "We can also treat\n",
    "text as a one-dimensional image, so that we can use one-dimensional\n",
    "convolutional neural networks to capture associations between adjacent\n",
    "words. This section describes a groundbreaking approach to applying\n",
    "convolutional neural networks to text analysis: textCNN :cite:`Kim.2014`. First, import the packages and modules required for the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-dimensional Convolutional Layer\n",
    "\n",
    "Before introducing the model, let us explain how a one-dimensional convolutional layer works. Like a two-dimensional convolutional layer, a one-dimensional convolutional layer uses a one-dimensional cross-correlation operation. In the one-dimensional cross-correlation operation, the convolution window starts from the leftmost side of the input array and slides on the input array from left to right successively. When the convolution window slides to a certain position, the input subarray in the window and kernel array are multiplied and summed by element to get the element at the corresponding location in the output array. As shown in Figure 12.4, the input is a one-dimensional array with a width of 7 and the width of the kernel array is 2. As we can see, the output width is $7-2+1=6$ and the first element is obtained by performing multiplication by element on the leftmost input subarray with a width of 2 and kernel array and then summing the results.\n",
    "\n",
    "![One-dimensional cross-correlation operation. The shaded parts are the first output element as well as the input and kernel array elements used in its calculation: $0\\times1+1\\times2=2$. ](../img/conv1d.svg)\n",
    "\n",
    "Next, we implement one-dimensional cross-correlation in the `corr1d` function. It accepts the input array `X` and kernel array `K` and outputs the array `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [],
   "source": [
    "def corr1d(X, K):\n",
    "    w = K.shape[0]\n",
    "    Y = nd.zeros((X.shape[0] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        Y[i] = (X[i: i + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will reproduce the results of the one-dimensional cross-correlation operation in Figure 12.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 2.  5.  8. 11. 14. 17.]\n",
       "<NDArray 6 @cpu(0)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, K = nd.array([0, 1, 2, 3, 4, 5, 6]), nd.array([1, 2])\n",
    "corr1d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The one-dimensional cross-correlation operation for multiple input channels is also similar to the two-dimensional cross-correlation operation for multiple input channels. On each channel, it performs the one-dimensional cross-correlation operation on the kernel and its corresponding input and adds the results of the channels to get the output. Figure 12.5 shows a one-dimensional cross-correlation operation with three input channels.\n",
    "\n",
    "![One-dimensional cross-correlation operation with three input channels. The shaded parts are the first output element as well as the input and kernel array elements used in its calculation: $0\\times1+1\\times2+1\\times3+2\\times4+2\\times(-1)+3\\times(-3)=2$. ](../img/conv1d-channel.svg)\n",
    "\n",
    "Now, we reproduce the results of the one-dimensional cross-correlation operation with multi-input channel in Figure 12.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[ 2.  8. 14. 20. 26. 32.]\n",
       "<NDArray 6 @cpu(0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr1d_multi_in(X, K):\n",
    "    # First, we traverse along the 0th dimension (channel dimension) of X and\n",
    "    # K. Then, we add them together by using * to turn the result list into a\n",
    "    # positional argument of the add_n function\n",
    "    return nd.add_n(*[corr1d(x, k) for x, k in zip(X, K)])\n",
    "\n",
    "X = nd.array([[0, 1, 2, 3, 4, 5, 6],\n",
    "              [1, 2, 3, 4, 5, 6, 7],\n",
    "              [2, 3, 4, 5, 6, 7, 8]])\n",
    "K = nd.array([[1, 2], [3, 4], [-1, -3]])\n",
    "corr1d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of a two-dimensional cross-correlation operation tells us that a one-dimensional cross-correlation operation with multiple input channels can be regarded as a two-dimensional cross-correlation operation with a single input channel. As shown in Figure 12.6, we can also present the one-dimensional cross-correlation operation with multiple input channels in Figure 12.5 as the equivalent two-dimensional cross-correlation operation with a single input channel. Here, the height of the kernel is equal to the height of the input.\n",
    "\n",
    "![Two-dimensional cross-correlation operation with a single input channel. The highlighted parts are the first output element and the input and kernel array elements used in its calculation: $2\\times(-1)+3\\times(-3)+1\\times3+2\\times4+0\\times1+1\\times2=2$. ](../img/conv1d-2d.svg)\n",
    "\n",
    "Both the outputs in Figure 12.4 and Figure 12.5 have only one channel. We\n",
    "discussed how to specify multiple output channels in a two-dimensional\n",
    "convolutional layer in\n",
    ":numref:`chapter_channels`.\n",
    "Similarly,\n",
    "we can also specify multiple output channels in the one-dimensional\n",
    "convolutional layer to extend the model parameters in the convolutional layer.\n",
    "\n",
    "\n",
    "## Max-Over-Time Pooling Layer\n",
    "\n",
    "Similarly, we have a one-dimensional pooling layer. The max-over-time pooling layer used in TextCNN actually corresponds to a one-dimensional global maximum pooling layer. Assuming that the input contains multiple channels, and each channel consists of values on different time steps, the output of each channel will be the largest value of all time steps in the channel. Therefore, the input of the max-over-time pooling layer can have different time steps on each channel.\n",
    "\n",
    "To improve computing performance, we often combine timing examples of different lengths into a mini-batch and make the lengths of each timing example in the batch consistent by appending special characters (such as 0) to the end of shorter examples. Naturally, the added special characters have no intrinsic meaning. Because the main purpose of the max-over-time pooling layer is to capture the most important features of timing, it usually allows the model to be unaffected by the manually added characters.\n",
    "\n",
    "## The TextCNN Model\n",
    "\n",
    "TextCNN mainly uses a one-dimensional convolutional layer and max-over-time pooling layer. Suppose the input text sequence consists of $n$ words, and each word is represented by a $d$-dimension word vector. Then the input example has a width of $n$, a height of 1, and $d$ input channels. The calculation of textCNN can be mainly divided into the following steps:\n",
    "\n",
    "1. Define multiple one-dimensional convolution kernels and use them to perform convolution calculations on the inputs. Convolution kernels with different widths may capture the correlation of different numbers of adjacent words.\n",
    "2. Perform max-over-time pooling on all output channels, and then concatenate the pooling output values of these channels in a vector.\n",
    "3. The concatenated vector is transformed into the output for each category through the fully connected layer. A dropout layer can be used in this step to deal with overfitting.\n",
    "\n",
    "![TextCNN design. ](../img/textcnn.svg)\n",
    "\n",
    "Figure 12.7 gives an example to illustrate the textCNN. The input here is a sentence with 11 words, with each word represented by a 6-dimensional word vector. Therefore, the input sequence has a width of 11 and 6 input channels. We assume there are two one-dimensional convolution kernels with widths of 2 and 4, and 4 and 5 output channels, respectively. Therefore, after one-dimensional convolution calculation, the width of the four output channels is $11-2+1=10$, while the width of the other five channels is $11-4+1=8$. Even though the width of each channel is different, we can still perform max-over-time pooling for each channel and concatenate the pooling outputs of the 9 channels into a 9-dimensional vector. Finally, we use a fully connected layer to transform the 9-dimensional vector into a 2-dimensional output: positive sentiment and negative sentiment predictions.\n",
    "\n",
    "Next, we will implement a textCNN model. Compared with the previous section, in addition to replacing the recurrent neural network with a one-dimensional convolutional layer, here we use two embedding layers, one with a fixed weight and another that participates in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [],
   "source": [
    "class TextCNN(nn.Block):\n",
    "    def __init__(self, vocab_size, embed_size, kernel_sizes, num_channels,\n",
    "                 **kwargs):\n",
    "        super(TextCNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # The embedding layer does not participate in training\n",
    "        self.constant_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.decoder = nn.Dense(2)\n",
    "        # The max-over-time pooling layer has no weight, so it can share an\n",
    "        # instance\n",
    "        self.pool = nn.GlobalMaxPool1D()\n",
    "        # Create multiple one-dimensional convolutional layers\n",
    "        self.convs = nn.Sequential()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.add(nn.Conv1D(c, k, activation='relu'))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Concatenate the output of two embedding layers with shape of\n",
    "        # (batch size, number of words, word vector dimension) by word vector\n",
    "        embeddings = nd.concat(\n",
    "            self.embedding(inputs), self.constant_embedding(inputs), dim=2)\n",
    "        # According to the input format required by Conv1D, the word vector\n",
    "        # dimension, that is, the channel dimension of the one-dimensional\n",
    "        # convolutional layer, is transformed into the previous dimension\n",
    "        embeddings = embeddings.transpose((0, 2, 1))\n",
    "        # For each one-dimensional convolutional layer, after max-over-time\n",
    "        # pooling, an NDArray with the shape of (batch size, channel size, 1)\n",
    "        # can be obtained. Use the flatten function to remove the last\n",
    "        # dimension and then concatenate on the channel dimension\n",
    "        encoding = nd.concat(*[nd.flatten(\n",
    "            self.pool(conv(embeddings))) for conv in self.convs], dim=1)\n",
    "        # After applying the dropout method, use a fully connected layer to\n",
    "        # obtain the output\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a TextCNN instance. It has 3 convolutional layers with kernel widths of 3, 4, and 5, all with 100 output channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, kernel_sizes, nums_channels = 100, [3, 4, 5], [100, 100, 100]\n",
    "net = TextCNN(len(vocab), embed_size, kernel_sizes, nums_channels)\n",
    "net.initialize(init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained Word Vectors\n",
    "\n",
    "As in the previous section, load pre-trained 100-dimensional GloVe word vectors and initialize the embedding layers `embedding` and `constant_embedding`. Here, the former participates in training while the latter has a fixed weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "net.embedding.weight.set_data(embeds)\n",
    "net.embedding.collect_params().setattr('grad_req', 'null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Model\n",
    "\n",
    "Now we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "30"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.015, train acc 0.996, test acc 0.848\n",
      "2521.4 exampes/sec on [gpu(0)]\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr})\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "train(net, train_iter, test_iter, loss, trainer, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use the trained model to the classify sentiments of two simple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* We can use one-dimensional convolution to process and analyze timing data.\n",
    "* A one-dimensional cross-correlation operation with multiple input channels can be regarded as a two-dimensional cross-correlation operation with a single input channel.\n",
    "* The input of the max-over-time pooling layer can have different numbers of time steps on each channel.\n",
    "* TextCNN mainly uses a one-dimensional convolutional layer and max-over-time pooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Recurrent Neural Networks\n",
    "\n",
    "In this section, we will apply\n",
    "pre-trained word vectors and bidirectional recurrent neural networks with\n",
    "multiple hidden layers :cite:`Maas.Daly.Pham.ea.2011`. We will use them to\n",
    "determine whether a text sequence of indefinite length contains positive or\n",
    "negative emotion. Import the required package or module before starting the\n",
    "experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a Recurrent Neural Network Model\n",
    "\n",
    "In this model, each word first obtains a feature vector from the embedding\n",
    "layer. Then, we further encode the feature sequence using a bidirectional\n",
    "recurrent neural network to obtain sequence information. Finally, we transform\n",
    "the encoded sequence information to output through the fully connected\n",
    "layer. Specifically, we can concatenate hidden states of bidirectional\n",
    "long-short term memory in the initial time step and final time step and pass it\n",
    "to the output layer classification as encoded feature sequence information. In\n",
    "the `BiRNN` class implemented below, the `Embedding` instance is the embedding\n",
    "layer, the `LSTM` instance is the hidden layer for sequence encoding, and the\n",
    "`Dense` instance is the output layer for generated classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "46"
    }
   },
   "outputs": [],
   "source": [
    "class BiRNN(nn.Block):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, **kwargs):\n",
    "        super(BiRNN, self).__init__(**kwargs)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        # Set Bidirectional to True to get a bidirectional recurrent neural\n",
    "        # network\n",
    "        self.encoder = rnn.LSTM(num_hiddens, num_layers=num_layers,\n",
    "                                bidirectional=True, input_size=embed_size)\n",
    "        self.decoder = nn.Dense(2)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # The shape of inputs is (batch size, number of words). Because LSTM\n",
    "        # needs to use sequence as the first dimension, the input is\n",
    "        # transformed and the word feature is then extracted. The output shape\n",
    "        # is (number of words, batch size, word vector dimension).\n",
    "        embeddings = self.embedding(inputs.T)\n",
    "        # Since the input (embeddings) is the only argument passed into\n",
    "        # rnn.LSTM, it only returns the hidden states of the last hidden layer\n",
    "        # at different time step (outputs). The shape of outputs is\n",
    "        # (number of words, batch size, 2 * number of hidden units).\n",
    "        outputs = self.encoder(embeddings)\n",
    "        # Concatenate the hidden states of the initial time step and final\n",
    "        # time step to use as the input of the fully connected layer. Its\n",
    "        # shape is (batch size, 4 * number of hidden units)\n",
    "        encoding = nd.concat(outputs[0], outputs[-1])\n",
    "        outs = self.decoder(encoding)\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bidirectional recurrent neural network with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, ctx = 100, 100, 2, d2l.try_all_gpus()\n",
    "net = BiRNN(len(vocab), embed_size, num_hiddens, num_layers)\n",
    "net.initialize(init.Xavier(), ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained Word Vectors\n",
    "\n",
    "Because the training data set for sentiment classification is not very large, in order to deal with overfitting, we will directly use word vectors pre-trained on a larger corpus as the feature vectors of all words. Here, we load a 100-dimensional GloVe word vector for each word in the dictionary `vocab`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the word vectors that in our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49342, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = glove_embedding[vocab.idx_to_token]\n",
    "embeds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will use these word vectors as feature vectors for each word in the reviews. Note that the dimensions of the pre-trained word vectors need to be consistent with the embedding layer output size `embed_size` in the created model. In addition, we no longer update these word vectors during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "47"
    }
   },
   "outputs": [],
   "source": [
    "net.embedding.weight.set_data(embeds)\n",
    "net.embedding.collect_params().setattr('grad_req', 'null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate the Model\n",
    "\n",
    "Now, we can start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "48"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.302, train acc 0.871, test acc 0.841\n",
      "850.4 exampes/sec on [gpu(0)]\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr})\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "train(net, train_iter, test_iter, loss, trainer, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, define the prediction function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, use the trained model to classify the sentiments of two simple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "50"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "* Text classification transforms a sequence of text of indefinite length into a category of text. This is a downstream application of word embedding.\n",
    "* We can apply pre-trained word vectors and recurrent neural networks to classify the emotions in a text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Using Recurrent Neural Networks with Self-Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.HybridBlock):\n",
    "    def __init__(self, num_atention_units, num_attention_channels, **kwargs):\n",
    "        super(SelfAttention, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.proj_query = nn.Dense(num_atention_units, activation='tanh', flatten=False)\n",
    "            self.parametric_key = nn.Dense(num_attention_channels, activation=None, flatten=False)\n",
    "\n",
    "    def hybrid_forward(self, F, query):\n",
    "        # query shape: [batch_size, seq_len, embedding_width]\n",
    "        # projected query shape: [batch_size, seq_len, num_atention_units]\n",
    "        query = self.proj_query(query)\n",
    "        # scores shape: [batch_size, seq_len, attention_channels]\n",
    "        scores = self.parametric_key(query)\n",
    "\n",
    "        # attention_weights shape: [batch_size,  att_hops, seq_len]\n",
    "        attention_weights = F.softmax(F.transpose(scores, axes=(0, 2, 1)), axis=-1)\n",
    "        # output shape [batch_size, att_hops, embedding_width]\n",
    "        output = F.batch_dot(attention_weights, query)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class AttentiveBiLSTM(nn.HybridBlock):\n",
    "    \"\"\"Lin et al.: A Structured Self-Attentive Sentence Embedding. ICLR 2017\"\"\"\n",
    "    def __init__(self, vocab_len, embed_size, num_hiddens, num_layers,\n",
    "                 num_attention_units, num_attention_channels, **kwargs):\n",
    "        super(AttentiveBiLSTM, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.embedding = nn.Embedding(vocab_len, embed_size)\n",
    "            self.encoder = rnn.LSTM(num_hiddens, num_layers=num_layers, bidirectional=True)\n",
    "            self.attention = SelfAttention(num_attention_units, num_attention_channels)\n",
    "            self.decoder = nn.Dense(2)\n",
    "\n",
    "    def hybrid_forward(self, F, inputs):\n",
    "        # The shape of inputs is (batch size, number of words). Because LSTM\n",
    "        # needs to use sequence as the first dimension, the input is\n",
    "        # transformed and the word feature is then extracted. The output shape\n",
    "        # is (number of words, batch size, word vector dimension).\n",
    "        embeddings = self.embedding(F.transpose(inputs))\n",
    "        # The shape of states is (number of words, batch size, 2 * number of\n",
    "        # hidden units).\n",
    "        states = self.encoder(embeddings)\n",
    "        context_vec, att_weights = self.attention(F.transpose(states, (1, 0, 2)))\n",
    "        \n",
    "        outputs = self.decoder(F.flatten(context_vec))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:25.447434Z",
     "start_time": "2019-04-18T18:37:20.149858Z"
    }
   },
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, ctx = 100, 100, 2, d2l.try_all_gpus()\n",
    "natt_unit, natt_channel = 500, 2\n",
    "\n",
    "net = AttentiveBiLSTM(len(vocab), embed_size, num_hiddens, num_layers,\n",
    "                            natt_unit, natt_channel)\n",
    "net.initialize(init.Xavier(), ctx=ctx)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load Pre-trained Word Vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:40.206184Z",
     "start_time": "2019-04-18T18:37:25.449068Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_to_vec = glove_embedding[vocab.idx_to_token]\n",
    "idx_to_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Use these word vectors as feature vectors for each word in the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:37:40.210859Z",
     "start_time": "2019-04-18T18:37:40.207714Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "47"
    }
   },
   "outputs": [],
   "source": [
    "net.embedding.weight.set_data(idx_to_vec)\n",
    "net.embedding.collect_params().setattr('grad_req', 'null')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Train and Evaluate the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.801349Z",
     "start_time": "2019-04-18T18:37:40.212205Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "48"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on [gpu(0)]\n",
      "epoch 1, loss 0.4950, train acc 0.751, test acc 0.831, time 42.9 sec\n",
      "epoch 2, loss 0.3545, train acc 0.846, test acc 0.854, time 42.8 sec\n",
      "epoch 3, loss 0.3073, train acc 0.870, test acc 0.868, time 42.7 sec\n",
      "epoch 4, loss 0.2863, train acc 0.880, test acc 0.872, time 42.5 sec\n",
      "epoch 5, loss 0.2465, train acc 0.899, test acc 0.873, time 42.8 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.01, 5\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': lr})\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "train(net, train_iter, test_iter, loss, trainer, num_epochs, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Then, use the trained model to classify the sentiments of two simple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.814658Z",
     "start_time": "2019-04-18T18:41:09.808150Z"
    },
    "attributes": {
     "classes": [],
     "id": "",
     "n": "50"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-18T18:41:09.821180Z",
     "start_time": "2019-04-18T18:41:09.816015Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(net, vocab, 'this movie is so bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
